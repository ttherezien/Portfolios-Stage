{"version":3,"file":"js/461.6d343ce2.js","mappings":"0KAAA,IAAIA,EAAS,WAAkB,IAAIC,EAAIC,KAAQD,EAAIE,MAAMC,GAAG,OAAOH,EAAII,GAAG,EAC1E,EACIC,EAAkB,CAAC,WAAY,IAAIL,EAAIC,KAAKE,EAAGH,EAAIE,MAAMC,GAAG,OAAOA,EAAG,MAAM,CAACA,EAAG,OAAO,CAACG,MAAM,CAAC,KAAO,yEAAyE,IAAM,gBAAgBH,EAAG,MAAM,CAACI,YAAY,sBAAsB,CAACJ,EAAG,KAAK,CAACI,YAAY,sBAAsB,CAACP,EAAIQ,GAAG,2CAA2CL,EAAG,MAAM,CAACI,YAAY,4DAA4D,CAACJ,EAAG,MAAM,CAACI,YAAY,iDAAiD,CAACJ,EAAG,KAAK,CAACI,YAAY,8BAA8B,CAACP,EAAIQ,GAAG,+CAA+CL,EAAG,IAAI,CAACH,EAAIQ,GAAG,wHAAwHL,EAAG,MAAM,CAACI,YAAY,iDAAiD,CAACJ,EAAG,KAAK,CAACI,YAAY,8BAA8B,CAACP,EAAIQ,GAAG,qCAAqCL,EAAG,KAAK,CAACI,YAAY,8BAA8B,CAACJ,EAAG,KAAK,CAACH,EAAIQ,GAAG,+CAA+CL,EAAG,KAAK,CAACH,EAAIQ,GAAG,mDAAmDL,EAAG,KAAK,CAACH,EAAIQ,GAAG,yCAAyCL,EAAG,MAAM,CAACI,YAAY,iDAAiD,CAACJ,EAAG,KAAK,CAACI,YAAY,8BAA8B,CAACP,EAAIQ,GAAG,oCAAoCL,EAAG,IAAI,CAACH,EAAIQ,GAAG,8DAA8DL,EAAG,KAAK,CAACI,YAAY,8BAA8B,CAACP,EAAIQ,GAAG,6BAA6BL,EAAG,KAAK,CAACI,YAAY,wCAAwC,CAACJ,EAAG,KAAK,CAACH,EAAIQ,GAAG,cAAcL,EAAG,KAAK,CAACH,EAAIQ,GAAG,iBAAiBL,EAAG,KAAK,CAACH,EAAIQ,GAAG,UAAUL,EAAG,KAAK,CAACH,EAAIQ,GAAG,cAAcL,EAAG,KAAK,CAACH,EAAIQ,GAAG,oBAAoBL,EAAG,KAAK,CAACH,EAAIQ,GAAG,8BAA8BL,EAAG,KAAK,CAACH,EAAIQ,GAAG,+BAA+BL,EAAG,KAAK,CAACI,YAAY,8BAA8B,CAACP,EAAIQ,GAAG,6BAA6BL,EAAG,KAAK,CAACI,YAAY,wCAAwC,CAACJ,EAAG,KAAK,CAACH,EAAIQ,GAAG,SAASL,EAAG,KAAK,CAACH,EAAIQ,GAAG,oBAAoBL,EAAG,KAAK,CAACH,EAAIQ,GAAG,kBAAkBL,EAAG,MAAM,CAACI,YAAY,kEAAkE,CAACJ,EAAG,MAAM,CAACG,MAAM,CAAC,IAAMG,EAAQ,MAA4B,IAAM,MAAMN,EAAG,MAAM,CAACG,MAAM,CAAC,IAAMG,EAAQ,MAAwB,IAAM,MAAMN,EAAG,MAAM,CAACG,MAAM,CAAC,IAAMG,EAAQ,MAA6B,IAAM,MAAMN,EAAG,MAAM,CAACG,MAAM,CAAC,IAAMG,EAAQ,KAA8B,IAAM,UAAUN,EAAG,MAAM,CAACI,YAAY,sBAAsB,CAACJ,EAAG,KAAK,CAACI,YAAY,sBAAsB,CAACP,EAAIQ,GAAG,yBAAyBL,EAAG,MAAM,CAACI,YAAY,4DAA4D,CAACJ,EAAG,MAAM,CAACI,YAAY,iDAAiD,CAACJ,EAAG,KAAK,CAACI,YAAY,0BAA0B,CAACP,EAAIQ,GAAG,0CAA0CL,EAAG,IAAI,CAACI,YAAY,iBAAiB,CAACP,EAAIQ,GAAG,iEAAiEL,EAAG,KAAK,CAACI,YAAY,mCAAmC,CAACJ,EAAG,KAAK,CAACH,EAAIQ,GAAG,eAAeL,EAAG,KAAK,CAACH,EAAIQ,GAAG,oBAAoBL,EAAG,KAAK,CAACH,EAAIQ,GAAG,YAAYL,EAAG,KAAK,CAACH,EAAIQ,GAAG,gBAAgBL,EAAG,KAAK,CAACH,EAAIQ,GAAG,aAAaL,EAAG,IAAI,CAACH,EAAIQ,GAAG,gIAAgIL,EAAG,KAAK,CAACI,YAAY,mCAAmC,CAACP,EAAIQ,GAAG,8GAA8GL,EAAG,IAAI,CAACH,EAAIQ,GAAG,uRAAuRL,EAAG,KAAK,CAACI,YAAY,mCAAmC,CAACJ,EAAG,KAAK,CAACA,EAAG,IAAI,CAACH,EAAIQ,GAAG,oCAAoCR,EAAIQ,GAAG,mFAAmFL,EAAG,KAAK,CAACA,EAAG,IAAI,CAACH,EAAIQ,GAAG,mBAAmBR,EAAIQ,GAAG,+EAA+EL,EAAG,KAAK,CAACA,EAAG,IAAI,CAACH,EAAIQ,GAAG,kBAAkBR,EAAIQ,GAAG,0EAA0EL,EAAG,KAAK,CAACI,YAAY,mCAAmC,CAACP,EAAIQ,GAAG,2DAA2DL,EAAG,IAAI,CAACH,EAAIQ,GAAG,+MAA+ML,EAAG,KAAK,CAACI,YAAY,mCAAmC,CAACJ,EAAG,KAAK,CAACA,EAAG,IAAI,CAACH,EAAIQ,GAAG,0BAA0BR,EAAIQ,GAAG,iHAAiHL,EAAG,KAAK,CAACA,EAAG,IAAI,CAACH,EAAIQ,GAAG,+BAA+BR,EAAIQ,GAAG,4FAA4FL,EAAG,KAAK,CAACA,EAAG,IAAI,CAACH,EAAIQ,GAAG,8BAA8BR,EAAIQ,GAAG,wIAAwIL,EAAG,MAAM,CAACI,YAAY,iDAAiD,CAACJ,EAAG,KAAK,CAACI,YAAY,8BAA8B,CAACP,EAAIQ,GAAG,0CAA0CL,EAAG,IAAI,CAACI,YAAY,QAAQ,CAACP,EAAIQ,GAAG,OAAOL,EAAG,IAAI,CAACH,EAAIQ,GAAG,kDAAkDR,EAAIQ,GAAG,WAAWL,EAAG,IAAI,CAACH,EAAIQ,GAAG,6CAA6CR,EAAIQ,GAAG,6JAA6JL,EAAG,IAAI,CAACI,YAAY,QAAQ,CAACP,EAAIQ,GAAG,QAAQL,EAAG,IAAI,CAACH,EAAIQ,GAAG,SAASR,EAAIQ,GAAG,yUAAyUL,EAAG,MAAM,CAACI,YAAY,SAASD,MAAM,CAAC,IAAMG,EAAQ,MAAoB,IAAM,MAAMN,EAAG,IAAI,CAACI,YAAY,QAAQ,CAACP,EAAIQ,GAAG,QAAQL,EAAG,IAAI,CAACH,EAAIQ,GAAG,SAASR,EAAIQ,GAAG,mbAAmbL,EAAG,MAAM,CAACI,YAAY,SAASD,MAAM,CAAC,IAAMG,EAAQ,MAAoB,IAAM,UAAUN,EAAG,MAAM,CAACI,YAAY,sBAAsB,CAACJ,EAAG,KAAK,CAACI,YAAY,sBAAsB,CAACP,EAAIQ,GAAG,mBAAmBL,EAAG,MAAM,CAACI,YAAY,4DAA4D,CAACJ,EAAG,MAAM,CAACI,YAAY,iDAAiD,CAACJ,EAAG,KAAK,CAACI,YAAY,8BAA8B,CAACP,EAAIQ,GAAG,iCAAiCL,EAAG,IAAI,CAACH,EAAIQ,GAAG,OAAOL,EAAG,IAAI,CAACH,EAAIQ,GAAG,cAAcR,EAAIQ,GAAG,sBAAsBL,EAAG,IAAI,CAACH,EAAIQ,GAAG,mBAAmBR,EAAIQ,GAAG,gCAAgCL,EAAG,IAAI,CAACH,EAAIQ,GAAG,8BAA8BR,EAAIQ,GAAG,gDAAgDL,EAAG,IAAI,CAACH,EAAIQ,GAAG,uBAAuBR,EAAIQ,GAAG,yCAAyCL,EAAG,IAAI,CAACH,EAAIQ,GAAG,2CAA2CR,EAAIQ,GAAG,+BAA+BL,EAAG,IAAI,CAACH,EAAIQ,GAAG,sBAAsBR,EAAIQ,GAAG,QAAQL,EAAG,IAAI,CAACH,EAAIQ,GAAG,0BAA0BR,EAAIQ,GAAG,wEAAwEL,EAAG,MAAM,CAACI,YAAY,SAASD,MAAM,CAAC,IAAMG,EAAQ,MAAyB,IAAM,QAAQN,EAAG,MAAM,CAACI,YAAY,iDAAiD,CAACJ,EAAG,KAAK,CAACI,YAAY,8BAA8B,CAACP,EAAIQ,GAAG,0BAA0BL,EAAG,IAAI,CAACH,EAAIQ,GAAG,4CAA4CL,EAAG,IAAI,CAACI,YAAY,6CAA6CD,MAAM,CAAC,KAAO,mCAAmC,OAAS,WAAW,CAACN,EAAIQ,GAAG,2EAA6ER,EAAIQ,GAAG,QAAQL,EAAG,IAAI,CAACI,YAAY,kBAAkBD,MAAM,CAAC,KAAO,gEAAgE,OAAS,WAAW,CAACN,EAAIQ,GAAG,qBAAqBR,EAAIQ,GAAG,MAAML,EAAG,IAAI,CAACI,YAAY,kBAAkBD,MAAM,CAAC,KAAO,gEAAgE,OAAS,WAAW,CAACN,EAAIQ,GAAG,oBAAoBR,EAAIQ,GAAG,MAAML,EAAG,IAAI,CAACI,YAAY,kBAAkBD,MAAM,CAAC,KAAO,kEAAkE,OAAS,WAAW,CAACN,EAAIQ,GAAG,wBAAwBR,EAAIQ,GAAG,gMAAgML,EAAG,IAAI,CAACI,YAAY,QAAQ,CAACP,EAAIQ,GAAG,sQAAsQL,EAAG,IAAI,CAACI,YAAY,QAAQ,CAACP,EAAIQ,GAAG,0MAA0ML,EAAG,MAAM,CAACI,YAAY,iDAAiD,CAACJ,EAAG,KAAK,CAACI,YAAY,8BAA8B,CAACP,EAAIQ,GAAG,iBAAiBL,EAAG,IAAI,CAACI,YAAY,QAAQ,CAACP,EAAIQ,GAAG,kIAAkIL,EAAG,KAAK,CAACI,YAAY,8BAA8B,CAACJ,EAAG,KAAK,CAACH,EAAIQ,GAAG,uCAAuCL,EAAG,KAAK,CAACH,EAAIQ,GAAG,2DAA2DL,EAAG,IAAI,CAACI,YAAY,QAAQ,CAACP,EAAIQ,GAAG,gUAAgUL,EAAG,MAAM,CAACI,YAAY,iDAAiD,CAACJ,EAAG,KAAK,CAACI,YAAY,8BAA8B,CAACP,EAAIQ,GAAG,iBAAiBL,EAAG,IAAI,CAACI,YAAY,QAAQ,CAACP,EAAIQ,GAAG,8NAA8NL,EAAG,MAAM,CAACI,YAAY,SAASD,MAAM,CAAC,IAAMG,EAAQ,MAAgC,IAAM,MAAMN,EAAG,MAAM,CAACI,YAAY,SAASD,MAAM,CAAC,IAAMG,EAAQ,MAAgC,IAAM,MAAMN,EAAG,MAAM,CAACI,YAAY,SAASD,MAAM,CAAC,IAAMG,EAAQ,MAAgC,IAAM,MAAMN,EAAG,IAAI,CAACI,YAAY,QAAQ,CAACP,EAAIQ,GAAG,4cAA4cL,EAAG,IAAI,CAACH,EAAIQ,GAAG,0OAA0OL,EAAG,IAAI,CAACH,EAAIQ,GAAG,mGAAmGL,EAAG,MAAM,CAACI,YAAY,sBAAsB,CAACJ,EAAG,KAAK,CAACI,YAAY,sBAAsB,CAACP,EAAIQ,GAAG,+CAA+CL,EAAG,MAAM,CAACI,YAAY,4DAA4D,CAACJ,EAAG,MAAM,CAACI,YAAY,iDAAiD,CAACJ,EAAG,KAAK,CAACI,YAAY,8BAA8B,CAACP,EAAIQ,GAAG,mDAAmDL,EAAG,IAAI,CAACI,YAAY,QAAQ,CAACP,EAAIQ,GAAG,2EAA2EL,EAAG,KAAK,CAACI,YAAY,8BAA8B,CAACJ,EAAG,KAAK,CAACA,EAAG,IAAI,CAACH,EAAIQ,GAAG,aAAaR,EAAIQ,GAAG,kHAAkHL,EAAG,MAAM,CAACI,YAAY,OAAOD,MAAM,CAAC,IAAMG,EAAQ,MAA+B,IAAM,MAAMN,EAAG,KAAK,CAACA,EAAG,IAAI,CAACH,EAAIQ,GAAG,iBAAiBR,EAAIQ,GAAG,kLAAkLL,EAAG,KAAK,CAACH,EAAIQ,GAAG,qCAAqCL,EAAG,IAAI,CAACH,EAAIQ,GAAG,iCAAiCR,EAAIQ,GAAG,2CAA2CL,EAAG,IAAI,CAACI,YAAY,QAAQ,CAACP,EAAIQ,GAAG,uDAAuDL,EAAG,IAAI,CAACH,EAAIQ,GAAG,8BAA8BR,EAAIQ,GAAG,QAAQL,EAAG,IAAI,CAACH,EAAIQ,GAAG,oBAAoBR,EAAIQ,GAAG,8RAA8RL,EAAG,IAAI,CAACI,YAAY,QAAQ,CAACP,EAAIQ,GAAG,6RAA6RL,EAAG,MAAM,CAACI,YAAY,iDAAiD,CAACJ,EAAG,KAAK,CAACI,YAAY,8BAA8B,CAACP,EAAIQ,GAAG,uCAAuCL,EAAG,IAAI,CAACI,YAAY,QAAQ,CAACP,EAAIQ,GAAG,mQAAmQL,EAAG,IAAI,CAACI,YAAY,QAAQ,CAACP,EAAIQ,GAAG,uZAAuZL,EAAG,IAAI,CAACI,YAAY,QAAQ,CAACP,EAAIQ,GAAG,6UAA6UL,EAAG,IAAI,CAACI,YAAY,QAAQ,CAACP,EAAIQ,GAAG,uKAAuKL,EAAG,IAAI,CAACH,EAAIQ,GAAG,UAAUR,EAAIQ,GAAG,MAAML,EAAG,IAAI,CAACH,EAAIQ,GAAG,YAAYR,EAAIQ,GAAG,kBAAkBL,EAAG,IAAI,CAACH,EAAIQ,GAAG,WAAWR,EAAIQ,GAAG,4NACzne,G,UCuTA,GACAE,KAAA,YACAC,OAAAA,GACAC,EAAAA,GAAAC,MACA,GC9TwP,I,UCOpPC,GAAY,OACd,EACAf,EACAM,GACA,EACA,KACA,WACA,MAIF,EAAeS,EAAiB,O","sources":["webpack://portfolio-stage/./src/views/StageView.vue","webpack://portfolio-stage/src/views/StageView.vue","webpack://portfolio-stage/./src/views/StageView.vue?b916","webpack://portfolio-stage/./src/views/StageView.vue?dbce"],"sourcesContent":["var render = function render(){var _vm=this,_c=_vm._self._c;return _vm._m(0)\n}\nvar staticRenderFns = [function (){var _vm=this,_c=_vm._self._c;return _c('div',[_c('link',{attrs:{\"href\":\"https://cdnjs.cloudflare.com/ajax/libs/flowbite/2.3.0/flowbite.min.css\",\"rel\":\"stylesheet\"}}),_c('div',{staticClass:\"py-8 border-b mb-8\"},[_c('h1',{staticClass:\"text-2xl font-bold\"},[_vm._v(\"L'augmentation des données d'images\")])]),_c('div',{staticClass:\"grid grid-cols-1 gap-1 grid-flow md:grid-cols-2 md:gap-4\"},[_c('div',{staticClass:\"py-8 border rounded-lg shadow-md p-6 bg-white\"},[_c('h2',{staticClass:\"text-xl font-semibold mb-4\"},[_vm._v(\"Qu'est-ce que l'augmentation des images :\")]),_c('p',[_vm._v(\"L'augmentation des images, c'est simplement le fait d'obtenir de nouvelles images grâce à des images existantes.\")])]),_c('div',{staticClass:\"py-8 border rounded-lg shadow-md p-6 bg-white\"},[_c('h2',{staticClass:\"text-xl font-semibold mb-4\"},[_vm._v(\"Pourquoi augmenter les images :\")]),_c('ul',{staticClass:\"list-disc list-inside ml-4\"},[_c('li',[_vm._v(\"Pour augmenter la taille de notre dataset\")]),_c('li',[_vm._v(\"Pour améliorer la performance de notre modèle\")]),_c('li',[_vm._v(\"Pour éviter le surapprentissage\")])])]),_c('div',{staticClass:\"py-8 border rounded-lg shadow-md p-6 bg-white\"},[_c('h2',{staticClass:\"text-xl font-semibold mb-4\"},[_vm._v(\"Comment augmenter les images :\")]),_c('p',[_vm._v(\"Il existe plusieurs méthodes pour augmenter les images :\")]),_c('h3',{staticClass:\"text-lg font-semibold mt-4\"},[_vm._v(\"Les méthodes basiques :\")]),_c('ul',{staticClass:\"list-disc list-inside ml-4 space-y-2\"},[_c('li',[_vm._v(\"Rotation\")]),_c('li',[_vm._v(\"Translation\")]),_c('li',[_vm._v(\"Zoom\")]),_c('li',[_vm._v(\"Flipping\")]),_c('li',[_vm._v(\"Ajout de bruit\")]),_c('li',[_vm._v(\"Changement de luminosité\")]),_c('li',[_vm._v(\"Changement de contraste\")])]),_c('h3',{staticClass:\"text-lg font-semibold mt-4\"},[_vm._v(\"Les méthodes avancées :\")]),_c('ul',{staticClass:\"list-disc list-inside ml-4 space-y-2\"},[_c('li',[_vm._v(\"GAN\")]),_c('li',[_vm._v(\"Style transfer\")]),_c('li',[_vm._v(\"CycleGAN\")])])]),_c('div',{staticClass:\"grid grid-cols-2 py-8 border rounded-lg shadow-md p-6 bg-white\"},[_c('img',{attrs:{\"src\":require(\"@/assets/CatRotation.gif\"),\"alt\":\"\"}}),_c('img',{attrs:{\"src\":require(\"@/assets/CatZoom.gif\"),\"alt\":\"\"}}),_c('img',{attrs:{\"src\":require(\"@/assets/Normaltoflip.png\"),\"alt\":\"\"}}),_c('img',{attrs:{\"src\":require(\"@/assets/NormaltoNoise.png\"),\"alt\":\"\"}})])]),_c('div',{staticClass:\"py-8 border-b mb-8\"},[_c('h1',{staticClass:\"text-2xl font-bold\"},[_vm._v(\"Methode Classique\")])]),_c('div',{staticClass:\"grid grid-cols-1 gap-1 grid-flow md:grid-cols-2 md:gap-4\"},[_c('div',{staticClass:\"py-8 border rounded-lg shadow-md p-6 bg-white\"},[_c('h2',{staticClass:\"text-xl font-bold mb-4\"},[_vm._v(\"Bibliothèques d'Augmentation d'Image\")]),_c('p',{staticClass:\"font-semibold\"},[_vm._v(\"Voici quelques-unes des bibliothèques les plus populaires :\")]),_c('ul',{staticClass:\"py-2 list-disc list-inside ml-4\"},[_c('li',[_vm._v(\"Augmentor\")]),_c('li',[_vm._v(\"Albumentations\")]),_c('li',[_vm._v(\"ImgAug\")]),_c('li',[_vm._v(\"Transforms\")]),_c('li',[_vm._v(\"Keras\")])]),_c('p',[_vm._v(\"Pour simplifier l'utilisation, j'ai choisi deux bibliothèques en particulier, chacune adaptée à un cas d'usage spécifique.\")]),_c('h2',{staticClass:\"pt-6 text-xl font-semibold mb-4\"},[_vm._v(\"Mes choix se sont portés sur Albumentations et Keras, pour deux raisons différentes et deux cas précis :\")]),_c('p',[_vm._v(\"Albumentations est reconnue pour sa flexibilité et sa vitesse. Elle propose une large gamme de transformations qui peuvent être facilement appliquées à un dataset entier. Voici pourquoi Albumentations est un excellent choix pour l'augmentation des images de votre dataset :\")]),_c('ul',{staticClass:\"py-2 list-disc list-inside ml-4\"},[_c('li',[_c('b',[_vm._v(\"Richesse des transformations :\")]),_vm._v(\" Rotation, découpage, ajustement de la luminosité et du contraste, flou, etc.\")]),_c('li',[_c('b',[_vm._v(\"Performance :\")]),_vm._v(\" Conçue pour être rapide et efficace, même avec des datasets volumineux. \")]),_c('li',[_c('b',[_vm._v(\"Simplicité :\")]),_vm._v(\" Facile à intégrer dans des pipelines de pré-traitement existants.\")])]),_c('h2',{staticClass:\"pt-6 text-xl font-semibold mb-4\"},[_vm._v(\"Keras : Pour l'Augmentation des Images en Temps Réel \")]),_c('p',[_vm._v(\"Keras, avec son API intuitive, offre des fonctionnalités d'augmentation d'image en temps réel, idéal pour le traitement des images lors de l'entraînement des modèles. Les avantages de Keras incluent : \")]),_c('ul',{staticClass:\"py-2 list-disc list-inside ml-4\"},[_c('li',[_c('b',[_vm._v(\"Intégration fluide :\")]),_vm._v(\" S'intègre parfaitement avec les modèles Keras pour augmenter les images à la volée pendant l'entraînement.\")]),_c('li',[_c('b',[_vm._v(\"Transformations variées :\")]),_vm._v(\" Inclut des transformations communes comme la rotation, le zoom, le retournement, etc.\")]),_c('li',[_c('b',[_vm._v(\"Facilité d'utilisation :\")]),_vm._v(\" Grâce à son API conviviale, vous pouvez rapidement mettre en place l'augmentation d'image dans votre workflow d'entraînement.\")])])]),_c('div',{staticClass:\"py-8 border rounded-lg shadow-md p-6 bg-white\"},[_c('h2',{staticClass:\"text-xl font-semibold mb-4\"},[_vm._v(\"La Difference entre le DAP et le DAT\")]),_c('p',{staticClass:\"pt-2\"},[_vm._v(\"Le \"),_c('b',[_vm._v(\"Data Augmentation during Preprocessing (DAP)\")]),_vm._v(\" et le \"),_c('b',[_vm._v(\"Data Augmentation during Training (DAT)\")]),_vm._v(\" sont deux techniques utilisées pour améliorer les performances des modèles de machine learning en augmentant la diversité des données d'entraînement. \")]),_c('p',{staticClass:\"pt-2\"},[_vm._v(\" Le \"),_c('b',[_vm._v(\"DAP\")]),_vm._v(\" consiste à appliquer des transformations aux images avant le début de l'entraînement. Les images augmentées sont stockées et prêtes à être utilisées pour entraîner le modèle. Cette méthode permet de vérifier et valider les images augmentées avant l'entraînement, mais peut nécessiter un espace de stockage supplémentaire. \")]),_c('img',{staticClass:\"w-auto\",attrs:{\"src\":require(\"@/assets/DAP.png\"),\"alt\":\"\"}}),_c('p',{staticClass:\"pt-2\"},[_vm._v(\" Le \"),_c('b',[_vm._v(\"DAT\")]),_vm._v(\", en revanche, applique les transformations en temps réel pendant le processus d'entraînement. Les images sont augmentées dynamiquement à chaque époque, introduisant une variabilité continue qui peut améliorer la généralisation du modèle. Cette approche est plus exigeante en termes de mémoire et de puissance de calcul, mais elle n'augmente pas les besoins en stockage et permet une augmentation continue et variée des données. \")]),_c('img',{staticClass:\"w-auto\",attrs:{\"src\":require(\"@/assets/DAT.png\"),\"alt\":\"\"}})])]),_c('div',{staticClass:\"py-8 border-b mb-8\"},[_c('h1',{staticClass:\"text-2xl font-bold\"},[_vm._v(\"Le CycleGAN\")])]),_c('div',{staticClass:\"grid grid-cols-1 gap-1 grid-flow md:grid-cols-2 md:gap-4\"},[_c('div',{staticClass:\"py-8 border rounded-lg shadow-md p-6 bg-white\"},[_c('h2',{staticClass:\"text-xl font-semibold mb-4\"},[_vm._v(\"Qu'est-ce que le CycleGAN :\")]),_c('p',[_vm._v(\"Le \"),_c('b',[_vm._v(\"CycleGAN\")]),_vm._v(\" est un modèle de \"),_c('b',[_vm._v(\"deep learning\")]),_vm._v(\" qui permet de réaliser des \"),_c('b',[_vm._v(\"transformations d'images\")]),_vm._v(\" d'un domaine à un autre sans nécessiter de \"),_c('b',[_vm._v(\"données appariées\")]),_vm._v(\". Il est basé sur l'architecture des \"),_c('b',[_vm._v(\"GAN (Generative Adversarial Networks)\")]),_vm._v(\" et utilise un ensemble de \"),_c('b',[_vm._v(\"deux générateurs\")]),_vm._v(\" et \"),_c('b',[_vm._v(\"deux discriminateurs\")]),_vm._v(\" pour apprendre à transformer des images d'un domaine à un autre. \")]),_c('img',{staticClass:\"w-auto\",attrs:{\"src\":require(\"@/assets/CycleGAN.jpg\"),\"alt\":\"\"}})]),_c('div',{staticClass:\"py-8 border rounded-lg shadow-md p-6 bg-white\"},[_c('h2',{staticClass:\"text-xl font-semibold mb-4\"},[_vm._v(\"Pourquoi le CycleGAN\")]),_c('p',[_vm._v(\"Après la lecture du papier de recherche \"),_c('a',{staticClass:\"underline hover:no-underline font-semibold\",attrs:{\"href\":\"https://arxiv.org/abs/2403.10075\",\"target\":\"_blank\"}},[_vm._v(\"\\\"A survey of synthetic data augmentation methods in computer vision\\\" \")]),_vm._v(\" de \"),_c('a',{staticClass:\"hover:underline\",attrs:{\"href\":\"https://arxiv.org/search/cs?searchtype=author&query=Mumuni,+A\",\"target\":\"_blank\"}},[_vm._v(\"Alhassan Mumuni\")]),_vm._v(\", \"),_c('a',{staticClass:\"hover:underline\",attrs:{\"href\":\"https://arxiv.org/search/cs?searchtype=author&query=Mumuni,+F\",\"target\":\"_blank\"}},[_vm._v(\"Fuseini Mumuni\")]),_vm._v(\", \"),_c('a',{staticClass:\"hover:underline\",attrs:{\"href\":\"https://arxiv.org/search/cs?searchtype=author&query=Gerrar,+N+K\",\"target\":\"_blank\"}},[_vm._v(\"Nana Kobina Gerrar\")]),_vm._v(\" qui présente une revue des méthodes d'augmentation de données synthétiques en vision par ordinateur, j'ai fait un choix par rapport à nos compétence et à la simplicité de mise en place \")]),_c('p',{staticClass:\"pt-2\"},[_vm._v(\" Parmi les solutions que nous avons écartées, plusieurs nécessitaient l'utilisation de moteurs graphiques tels qu'Unreal Engine ou Unity. Ces technologies demandent des compétences spécifiques que nous ne possédons pas actuellement au sein du laboratoire. \")]),_c('p',{staticClass:\"pt-2\"},[_vm._v(\" De plus, le Cycle GAN est très simple à utiliser, et sa structure, étant relativement ancienne, bénéficie d'une abondance d'exemples et de tutoriels. Cela facilite grandement sa mise en place. \")])]),_c('div',{staticClass:\"py-8 border rounded-lg shadow-md p-6 bg-white\"},[_c('h2',{staticClass:\"text-xl font-semibold mb-4\"},[_vm._v(\"Objectif : \")]),_c('p',{staticClass:\"py-2\"},[_vm._v(\" Notre objectif est de pouvoir entrainer un Cycle GAN avec des images de panneaux solaires, de deux catégorie differentes : \")]),_c('ul',{staticClass:\"list-disc list-inside ml-4\"},[_c('li',[_vm._v(\"Les panneaux solaires en bon état\")]),_c('li',[_vm._v(\"Les panneaux solaires avec des fractures physiques \")])]),_c('p',{staticClass:\"py-2\"},[_vm._v(\" Le Cycle GAN devra être capable de transformer des images de panneaux solaires en bon état en images de panneaux solaires avec des fractures physiques, et vice versa. Cela nous permettra de générer un dataset synthétique pour entraîner nos modèles de détection de fractures sur des images de panneaux solaires. \")])]),_c('div',{staticClass:\"py-8 border rounded-lg shadow-md p-6 bg-white\"},[_c('h2',{staticClass:\"text-xl font-semibold mb-4\"},[_vm._v(\"Resultat : \")]),_c('p',{staticClass:\"py-2\"},[_vm._v(\" Nous avons réussi à entraîner un Cycle GAN sur un dataset de panneaux solaires en bon état et de panneaux solaires avec des fractures physiques. Voici un aperçu des résultats obtenus au bout de 60h d'entrainement : \")]),_c('img',{staticClass:\"w-auto\",attrs:{\"src\":require(\"@/assets/CycleGANResult1.png\"),\"alt\":\"\"}}),_c('img',{staticClass:\"w-auto\",attrs:{\"src\":require(\"@/assets/CycleGANResult2.png\"),\"alt\":\"\"}}),_c('img',{staticClass:\"w-auto\",attrs:{\"src\":require(\"@/assets/CycleGANResult3.png\"),\"alt\":\"\"}}),_c('p',{staticClass:\"py-2\"},[_vm._v(\" Les images générées par le Cycle GAN sont convaincantes et montrent des résultats prometteurs. Cependant, elles ne sont pas encore suffisamment réalistes pour être utilisées dans un contexte de production. La suite du travail consisterais à améliorer la qualité des images générées par le Cycle GAN soit en utilisant un dataset plus large, soit en ajustant les hyperparamètres du modèle, soit en patientant pour que le modèle s'entraine plus longtemps. \")]),_c('p',[_vm._v(\" Le problème est que nous ne pouvons pas augmenter la taille du dataset en raison des contraintes spécifiques au projet. De plus, ajuster les hyperparamètres et les temps d'entraînement entraînera un coût de temps significatif. \")]),_c('p',[_vm._v(\" C'est donc une piste très prometteuse, mais qui n'a pas encore été pleinement explorée. \")])])]),_c('div',{staticClass:\"py-8 border-b mb-8\"},[_c('h1',{staticClass:\"text-2xl font-bold\"},[_vm._v(\"Les compétences aquises lors du stage :\")])]),_c('div',{staticClass:\"grid grid-cols-1 gap-1 grid-flow md:grid-cols-2 md:gap-4\"},[_c('div',{staticClass:\"py-8 border rounded-lg shadow-md p-6 bg-white\"},[_c('h2',{staticClass:\"text-xl font-semibold mb-4\"},[_vm._v(\"Développement d’applications durant mon stage\")]),_c('p',{staticClass:\"py-2\"},[_vm._v(\" Pendant mon stage, j'ai réalisé plusieurs sites web et API simples :\")]),_c('ul',{staticClass:\"list-disc list-inside ml-4\"},[_c('li',[_c('b',[_vm._v(\"Une API\")]),_vm._v(\" permettant d'augmenter des images avec des méthodes de base, dotée d'une interface utilisateur très simple.\")]),_c('img',{staticClass:\"py-2\",attrs:{\"src\":require(\"@/assets/DataAugmentAPI.png\"),\"alt\":\"\"}}),_c('li',[_c('b',[_vm._v(\"Un site web\")]),_vm._v(\" permettant de visualiser facilement les scores de similarité entre images (pour détecter par exemple les doublons), calculés préalablement et stockés dans un fichier JSON.\")]),_c('li',[_vm._v(\"Une tentative de mise en place d'\"),_c('b',[_vm._v(\"un modèle de classification\")]),_vm._v(\" basé sur la similarité syntaxique.\")])]),_c('p',{staticClass:\"py-2\"},[_vm._v(\" J'ai acquis de l'expérience avec des outils comme \"),_c('b',[_vm._v(\"Flask, TensorFlow, Keras\")]),_vm._v(\" et \"),_c('b',[_vm._v(\"Albumentations\")]),_vm._v(\" en Python. Sans cahier des charges précis, j'ai pu adopter une approche flexible pour le développement et la création d'outils. Ces derniers m'ont permis d'améliorer la visualisation des résultats de mes modèles. Leur simplicité, conception et ergonomie les rendent accessibles. \")]),_c('p',{staticClass:\"py-2\"},[_vm._v(\" Cependant, ces outils étant destinés à un usage personnel, ils manquent d'ergonomie et n'ont pas été testés rigoureusement. Leur développement, généralement réalisé en deux jours maximum, ne les préparait pas à une utilisation à long terme en cas de modifications de fichiers.\")])]),_c('div',{staticClass:\"py-8 border rounded-lg shadow-md p-6 bg-white\"},[_c('h2',{staticClass:\"text-xl font-semibold mb-4\"},[_vm._v(\"Gestion des données d'information\")]),_c('p',{staticClass:\"py-2\"},[_vm._v(\" Mon rôle durant mon stage incluait la gestion des données d'information, principalement axée sur des données photographiques. Contrairement aux bases de données relationnelles traditionnelles, mon travail ne nécessitait pas leur mise en place initiale.\")]),_c('p',{staticClass:\"py-2\"},[_vm._v(\" En revanche, j'ai consacré une partie significative de mon temps à la préparation des données pour l'entraînement des modèles. Cela comprenait le nettoyage, la transformation et l'organisation des données afin de les rendre utilisables par les algorithmes d'apprentissage automatique. De plus, j'ai été chargé du stockage efficace et de la visualisation claire des résultats produits par ces modèles.\")]),_c('p',{staticClass:\"py-2\"},[_vm._v(\" Un autre aspect crucial de mon travail était le tri des images. Ce processus, souvent fastidieux, a été simplifié par l'utilisation de méthodes de calcul de la similarité entre images. Cela m'a permis d'automatiser une partie du processus de tri et d'identifier rapidement les images similaires ou potentiellement redondantes.\")]),_c('p',{staticClass:\"py-2\"},[_vm._v(\" Pour cela, j'ai utilisé plusieurs formats de stockage comme JSON et CSV. J'ai manipulé ces formats en utilisant des bibliothèques populaires en Python telles que \"),_c('b',[_vm._v(\"json\")]),_vm._v(\", \"),_c('b',[_vm._v(\"pandas\")]),_vm._v(\" pour CSV, et \"),_c('b',[_vm._v(\"numpy\")]),_vm._v(\" pour le traitement numérique des données. Ces outils m'ont permis de naviguer efficacement à travers les données, de les préparer pour l'entraînement des modèles et de les utiliser dans diverses applications.\")])])])])\n}]\n\nexport { render, staticRenderFns }","<template>\n    <div>\n        <link href=\"https://cdnjs.cloudflare.com/ajax/libs/flowbite/2.3.0/flowbite.min.css\" rel=\"stylesheet\" />\n        <div class=\"py-8 border-b mb-8 \">\n            <h1 class=\"text-2xl font-bold\">L'augmentation des données d'images</h1>\n        </div>\n        <div class=\"grid grid-cols-1 gap-1 grid-flow md:grid-cols-2 md:gap-4\">\n\n            <div class=\"py-8 border rounded-lg shadow-md p-6 bg-white\">\n                <h2 class=\"text-xl font-semibold mb-4\">Qu'est-ce que l'augmentation des images :</h2>\n                <p>L'augmentation des images, c'est simplement le fait d'obtenir de nouvelles images grâce à des\n                    images existantes.</p>\n            </div>\n\n            <div class=\"py-8 border rounded-lg shadow-md p-6 bg-white\">\n                <h2 class=\"text-xl font-semibold mb-4\">Pourquoi augmenter les images :</h2>\n                <ul class=\"list-disc list-inside ml-4\">\n                    <li>Pour augmenter la taille de notre dataset</li>\n                    <li>Pour améliorer la performance de notre modèle</li>\n                    <li>Pour éviter le surapprentissage</li>\n                </ul>\n            </div>\n\n            <div class=\"py-8 border rounded-lg shadow-md p-6 bg-white\">\n                <h2 class=\"text-xl font-semibold mb-4\">Comment augmenter les images :</h2>\n                <p>Il existe plusieurs méthodes pour augmenter les images :</p>\n                <h3 class=\"text-lg font-semibold mt-4\">Les méthodes basiques :</h3>\n                <ul class=\"list-disc list-inside ml-4 space-y-2\">\n\n                    <li>Rotation</li>\n                    <li>Translation</li>\n                    <li>Zoom</li>\n                    <li>Flipping</li>\n                    <li>Ajout de bruit</li>\n                    <li>Changement de luminosité</li>\n                    <li>Changement de contraste</li>\n\n                </ul>\n                <h3 class=\"text-lg font-semibold mt-4\">Les méthodes avancées :</h3>\n                <ul class=\"list-disc list-inside ml-4 space-y-2\">\n                    <li>GAN</li>\n                    <li>Style transfer</li>\n                    <li>CycleGAN</li>\n                </ul>\n            </div>\n\n            <div class=\" grid grid-cols-2 py-8 border rounded-lg shadow-md p-6 bg-white\">\n                <img src=\"@/assets/CatRotation.gif\" alt=\"\">\n                <img src=\"@/assets/CatZoom.gif\" alt=\"\">\n                <img src=\"@/assets/Normaltoflip.png\" alt=\"\">\n                <img src=\"@/assets/NormaltoNoise.png\" alt=\"\">\n            </div>\n        </div>\n\n        <div class=\"py-8 border-b mb-8 \">\n            <h1 class=\"text-2xl font-bold\">Methode Classique</h1>\n        </div>\n        <div class=\"grid grid-cols-1 gap-1 grid-flow md:grid-cols-2 md:gap-4 \">\n\n            <div class=\"py-8 border rounded-lg shadow-md p-6 bg-white\">\n                <h2 class=\"text-xl font-bold mb-4\">Bibliothèques d'Augmentation d'Image</h2>\n                <p class=\"font-semibold\">Voici quelques-unes des bibliothèques les plus populaires :</p>\n                <ul class=\"py-2 list-disc list-inside ml-4 \">\n                    <li>Augmentor</li>\n                    <li>Albumentations</li>\n                    <li>ImgAug</li>\n                    <li>Transforms</li>\n                    <li>Keras</li>\n                </ul>\n                <p>Pour simplifier l'utilisation, j'ai choisi deux bibliothèques en particulier, chacune adaptée à un\n                    cas d'usage spécifique.</p>\n                <h2 class=\"pt-6 text-xl font-semibold mb-4\">Mes choix se sont portés sur Albumentations et Keras, pour\n                    deux raisons différentes et deux cas\n                    précis :</h2>\n                <p>Albumentations est reconnue pour sa flexibilité et sa vitesse. Elle propose une large gamme de\n                    transformations qui peuvent être facilement appliquées à un dataset entier. Voici pourquoi\n                    Albumentations est un excellent choix pour l'augmentation des images de votre dataset :</p>\n\n                <ul class=\"py-2 list-disc list-inside ml-4 \">\n                    <li><b>Richesse des transformations :</b> Rotation, découpage, ajustement de la luminosité et du\n                        contraste, flou, etc.</li>\n                    <li><b>Performance :</b> Conçue pour être rapide et efficace, même avec des datasets volumineux.\n                    </li>\n                    <li><b>Simplicité :</b> Facile à intégrer dans des pipelines de pré-traitement existants.</li>\n                </ul>\n\n                <h2 class=\"pt-6 text-xl font-semibold mb-4\">Keras : Pour l'Augmentation des Images en Temps Réel\n                </h2>\n                <p>Keras, avec son API intuitive, offre des fonctionnalités d'augmentation d'image en temps réel, idéal\n                    pour le traitement des images lors de l'entraînement des modèles. Les avantages de Keras incluent :\n                </p>\n                <ul class=\"py-2 list-disc list-inside ml-4 \">\n                    <li><b>Intégration fluide :</b> S'intègre parfaitement avec les modèles Keras pour augmenter les\n                        images à la volée pendant l'entraînement.</li>\n                    <li><b>Transformations variées :</b> Inclut des transformations communes comme la rotation, le zoom,\n                        le retournement, etc.</li>\n                    <li><b>Facilité d'utilisation :</b> Grâce à son API conviviale, vous pouvez rapidement mettre en\n                        place l'augmentation d'image dans votre workflow d'entraînement.</li>\n\n                </ul>\n\n            </div>\n            <div class=\"  py-8 border rounded-lg shadow-md p-6 bg-white\">\n                <h2 class=\"text-xl font-semibold mb-4\">La Difference entre le DAP et le DAT</h2>\n\n                <p class=\"pt-2\">Le <b>Data Augmentation during Preprocessing (DAP)</b> et le <b>Data Augmentation during\n                        Training\n                        (DAT)</b> sont\n                    deux techniques utilisées pour améliorer les performances des modèles de machine learning en\n                    augmentant la diversité des données d'entraînement.\n                </p>\n                <p class=\"pt-2\">\n                    Le <b>DAP</b> consiste à appliquer des transformations aux images avant le début de l'entraînement.\n                    Les\n                    images augmentées sont stockées et prêtes à être utilisées pour entraîner le modèle. Cette méthode\n                    permet de vérifier et valider les images augmentées avant l'entraînement, mais peut nécessiter un\n                    espace de stockage supplémentaire.\n                </p>\n                <img src=\"@/assets/DAP.png\" class=\"w-auto\" alt=\"\">\n                <p class=\"pt-2\">\n                    Le <b>DAT</b>, en revanche, applique les transformations en temps réel pendant le processus\n                    d'entraînement.\n                    Les images sont augmentées dynamiquement à chaque époque, introduisant une variabilité continue qui\n                    peut améliorer la généralisation du modèle. Cette approche est plus exigeante en termes de mémoire\n                    et de puissance de calcul, mais elle n'augmente pas les besoins en stockage et permet une\n                    augmentation continue et variée des données.\n                </p>\n\n\n                <img src=\"@/assets/DAT.png\" class=\"w-auto\" alt=\"\">\n\n            </div>\n        </div>\n\n        <div class=\"py-8 border-b mb-8 \">\n            <h1 class=\"text-2xl font-bold\">Le CycleGAN</h1>\n        </div>\n        <div class=\"grid grid-cols-1 gap-1 grid-flow md:grid-cols-2 md:gap-4\">\n            <div class=\"py-8 border rounded-lg shadow-md p-6 bg-white\">\n                <h2 class=\"text-xl font-semibold mb-4\">Qu'est-ce que le CycleGAN :</h2>\n                <p>Le <b>CycleGAN</b> est un modèle de <b>deep learning</b> qui permet de réaliser des\n                    <b>transformations d'images</b>\n                    d'un domaine à un autre sans nécessiter de <b>données appariées</b>. Il est basé sur l'architecture\n                    des <b>GAN\n                        (Generative Adversarial Networks)</b> et utilise un ensemble de <b>deux générateurs</b> et\n                    <b>deux discriminateurs</b>\n                    pour apprendre à transformer des images d'un domaine à un autre.\n                </p>\n\n                <img src=\"@/assets/CycleGAN.jpg\" class=\"w-auto\" alt=\"\">\n\n            </div>\n\n            <div class=\"py-8 border rounded-lg shadow-md p-6 bg-white\">\n                <h2 class=\"text-xl font-semibold mb-4\">Pourquoi le CycleGAN</h2>\n                <p>Après la lecture du papier de recherche\n                    <a class=\"underline hover:no-underline font-semibold\" href=\"https://arxiv.org/abs/2403.10075\"\n                        target=\"_blank\">\"A survey of synthetic\n                        data augmentation methods in computer vision\" </a>\n                    de <a href=\"https://arxiv.org/search/cs?searchtype=author&query=Mumuni,+A\" class=\"hover:underline\"\n                        target=\"_blank\">Alhassan Mumuni</a>,\n                    <a href=\"https://arxiv.org/search/cs?searchtype=author&query=Mumuni,+F\" class=\"hover:underline\"\n                        target=\"_blank\">Fuseini Mumuni</a>,\n                    <a href=\"https://arxiv.org/search/cs?searchtype=author&query=Gerrar,+N+K\" class=\"hover:underline \"\n                        target=\"_blank\">Nana Kobina Gerrar</a>\n                    qui présente une revue des méthodes d'augmentation de données synthétiques en vision par ordinateur,\n                    j'ai fait un choix par rapport à nos compétence et à la simplicité de mise en place\n                </p>\n                <p class=\"pt-2\"> Parmi les solutions que nous avons écartées, plusieurs nécessitaient l'utilisation de\n                    moteurs\n                    graphiques tels qu'Unreal Engine ou Unity. Ces technologies demandent des compétences spécifiques\n                    que nous ne possédons pas actuellement au sein du laboratoire. </p>\n\n                <p class=\"pt-2\"> De plus, le Cycle GAN est très simple à utiliser, et sa structure, étant relativement\n                    ancienne, bénéficie d'une abondance d'exemples et de tutoriels. Cela facilite grandement sa mise en\n                    place. </p>\n\n            </div>\n\n            <div class=\"py-8 border rounded-lg shadow-md p-6 bg-white\">\n\n                <h2 class=\"text-xl font-semibold mb-4\">Objectif : </h2>\n                <p class=\"py-2\">\n                    Notre objectif est de pouvoir entrainer un Cycle GAN avec des images de panneaux solaires, de deux\n                    catégorie differentes :\n\n\n                </p>\n                <ul class=\"list-disc list-inside ml-4 \">\n                    <li>Les panneaux solaires en bon état</li>\n                    <li>Les panneaux solaires avec des fractures physiques </li>\n                </ul>\n\n                <p class=\"py-2\">\n                    Le Cycle GAN devra être capable de transformer des images de panneaux solaires en bon état en images\n                    de panneaux solaires avec des fractures physiques, et vice versa. Cela nous permettra de générer un\n                    dataset synthétique pour entraîner nos modèles de détection de fractures sur des images de panneaux\n                    solaires.\n                </p>\n\n            </div>\n            <div class=\"py-8 border rounded-lg shadow-md p-6 bg-white\">\n\n                <h2 class=\"text-xl font-semibold mb-4\">Resultat : </h2>\n                <p class=\"py-2\">\n                    Nous avons réussi à entraîner un Cycle GAN sur un dataset de panneaux solaires en bon état et de\n                    panneaux solaires avec des fractures physiques. Voici un aperçu des résultats obtenus au bout de 60h\n                    d'entrainement :\n                </p>\n                <img src=\"@/assets/CycleGANResult1.png\" class=\"w-auto\" alt=\"\">\n                <img src=\"@/assets/CycleGANResult2.png\" class=\"w-auto\" alt=\"\">\n                <img src=\"@/assets/CycleGANResult3.png\" class=\"w-auto\" alt=\"\">\n                <p class=\"py-2\">\n                    Les images générées par le Cycle GAN sont convaincantes et montrent des résultats prometteurs.\n                    Cependant, elles ne sont pas encore suffisamment réalistes pour être utilisées dans un contexte de\n                    production. La suite du travail consisterais à améliorer la qualité des images générées par le\n                    Cycle GAN soit en utilisant un dataset plus large, soit en ajustant les hyperparamètres du modèle,\n                    soit en patientant pour que le modèle s'entraine plus longtemps.\n                </p>\n\n                <p>\n                    Le problème est que nous ne pouvons pas augmenter la taille du dataset en raison des contraintes\n                    spécifiques au projet. De plus, ajuster les hyperparamètres et les temps d'entraînement entraînera\n                    un coût de temps significatif.\n                </p>\n\n                <p>\n                    C'est donc une piste très prometteuse, mais qui n'a pas encore été pleinement explorée.\n\n                </p>\n            </div>\n        </div>\n\n        <div class=\"py-8 border-b mb-8 \">\n            <h1 class=\"text-2xl font-bold\">Les compétences aquises lors du stage :</h1>\n\n        </div>\n\n        <div class=\"grid grid-cols-1 gap-1 grid-flow md:grid-cols-2 md:gap-4\">\n            <div class=\"py-8 border rounded-lg shadow-md p-6 bg-white\">\n                <h2 class=\"text-xl font-semibold mb-4\">Développement d’applications durant mon stage</h2>\n\n                <p class=\"py-2\"> Pendant mon stage, j'ai réalisé plusieurs sites web et API simples :</p>\n                <ul class=\"list-disc list-inside ml-4\">\n                    <li><b>Une API</b> permettant d'augmenter des images avec des méthodes de base, dotée d'une\n                        interface utilisateur\n                        très simple.</li>\n                    <img class=\"py-2\" src=\"@/assets/DataAugmentAPI.png\" alt=\"\">\n                    <li><b>Un site web</b> permettant de visualiser facilement les scores de similarité entre images\n                        (pour détecter par\n                        exemple les doublons), calculés préalablement et stockés dans un fichier JSON.</li>\n                    <li>Une tentative de mise en place d'<b>un modèle de classification</b> basé sur la similarité\n                        syntaxique.</li>\n                </ul>\n\n                <p class=\"py-2\"> J'ai acquis de l'expérience avec des outils comme <b>Flask, TensorFlow, Keras</b> et\n                    <b>Albumentations</b> en Python.\n                    Sans cahier des charges précis, j'ai pu adopter une approche flexible pour le développement et la\n                    création\n                    d'outils. Ces derniers m'ont permis d'améliorer la visualisation des résultats de mes modèles. Leur\n                    simplicité,\n                    conception et ergonomie les rendent accessibles.\n                </p>\n\n                <p class=\"py-2\"> Cependant, ces outils étant destinés à un usage personnel, ils manquent d'ergonomie et\n                    n'ont pas été\n                    testés rigoureusement. Leur développement, généralement réalisé en deux jours maximum, ne les\n                    préparait pas à\n                    une utilisation à long terme en cas de modifications de fichiers.</p>\n            </div>\n\n\n            <div class=\"py-8 border rounded-lg shadow-md p-6 bg-white\">\n                <h2 class=\"text-xl font-semibold mb-4\">Gestion des données d'information</h2>\n\n                <p class=\"py-2\"> Mon rôle durant mon stage incluait la gestion des données d'information, principalement\n                    axée sur des données photographiques. Contrairement aux bases de données relationnelles\n                    traditionnelles, mon travail ne nécessitait pas leur mise en place initiale.</p>\n\n                <p class=\"py-2\"> En revanche, j'ai consacré une partie significative de mon temps à la préparation des\n                    données pour l'entraînement des modèles. Cela comprenait le nettoyage, la transformation et\n                    l'organisation des données afin de les rendre utilisables par les algorithmes d'apprentissage\n                    automatique. De plus, j'ai été chargé du stockage efficace et de la visualisation claire des\n                    résultats produits par ces modèles.</p>\n\n                <p class=\"py-2\"> Un autre aspect crucial de mon travail était le tri des images. Ce processus, souvent\n                    fastidieux, a été simplifié par l'utilisation de méthodes de calcul de la similarité entre images.\n                    Cela m'a permis d'automatiser une partie du processus de tri et d'identifier rapidement les images\n                    similaires ou potentiellement redondantes.</p>\n\n\n                <p class=\"py-2\"> Pour cela, j'ai utilisé plusieurs formats de stockage comme JSON et CSV. J'ai manipulé\n                    ces formats en utilisant des bibliothèques populaires en Python telles que <b>json</b>,\n                    <b>pandas</b> pour CSV, et <b>numpy</b> pour le traitement numérique des données. Ces\n                    outils m'ont permis de naviguer efficacement à travers les données, de les préparer pour\n                    l'entraînement des modèles et de les utiliser dans diverses applications.</p>\n\n            </div>\n\n        </div>\n\n\n\n    </div>\n\n\n\n\n</template>\n\n<script>\nimport 'flowbite';\nimport { Popover } from 'flowbite';\n\nexport default {\n    name: 'StageView',\n    mounted() {\n        Popover.init();\n    },\n};\n</script>\n\n<style scoped></style>","import mod from \"-!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js??clonedRuleSet-40.use[1]!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./StageView.vue?vue&type=script&lang=js\"; export default mod; export * from \"-!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js??clonedRuleSet-40.use[1]!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./StageView.vue?vue&type=script&lang=js\"","import { render, staticRenderFns } from \"./StageView.vue?vue&type=template&id=5b20855e&scoped=true\"\nimport script from \"./StageView.vue?vue&type=script&lang=js\"\nexport * from \"./StageView.vue?vue&type=script&lang=js\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/@vue/vue-loader-v15/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"5b20855e\",\n  null\n  \n)\n\nexport default component.exports"],"names":["render","_vm","this","_self","_c","_m","staticRenderFns","attrs","staticClass","_v","require","name","mounted","Popover","init","component"],"sourceRoot":""}